# -*- coding: UTF-8 -*-
'''

ä»£ç è¯´æ˜:    è®­ç»ƒæµç¨‹

Created on      2024/07/23 15:28:23
Author:         @Mr_Robot
State:          3d can run 
'''

import os

import time
import torch
import numpy as np
from tqdm import tqdm
# from torch.nn import CrossEntropyLoss
# from loss_function import Diceloss, crossEntropy_loss
# from torch.nn import CrossEntropyLoss
# from torchvision import transforms
# from torch.utils.data import DataLoader

# from torch.optim import Adam, SGD, RMSprop, AdamW
from torch.amp import autocast

# # åŠ è½½æœ¬åœ°æ¨¡å—
# from readDatasets.BraTS import BraTS21_3d
# from nets.unet3ds import UNet_3d_22M_32, UNet_3d_22M_64, UNet_3d_48M, UNet_3d_90M, init_weights_light, init_weights_pro
# from metrics import EvaluationMetrics

os.environ["CUDA_LAUNCH_BLOCKING"] = '1'
best_val_loss = float('inf')
start_epoch = 0

def train_one_epoch(model, train_loader, scaler, optimizer, loss_function, device):
    """
    ====è®­ç»ƒè¿‡ç¨‹====
    :param model: æ¨¡å‹
    :param metrics: è¯„ä¼°æŒ‡æ ‡
    :param train_loader: è®­ç»ƒæ•°æ®é›†
    :param val_loader: éªŒè¯æ•°æ®é›†
    :param scaler: ç¼©æ”¾å™¨
    :param optimizer: ä¼˜åŒ–å™¨
    :param loss_funtion: æŸå¤±å‡½æ•°
    :param device: è®¾å¤‡
    :param model_path: æ¨¡å‹è·¯å¾„
    """
    model.train()
    
    train_running_loss = 0.0
    
    train_et_loss = 0.0
    train_tc_loss = 0.0
    train_wt_loss = 0.0
    
    train_loader = tqdm(train_loader, desc=f"ğŸ› ï¸--Training", leave=False)
    
    for data in train_loader: # è¯»å–æ¯ä¸€ä¸ª batch
        # è·å–è¾“å…¥æ•°æ®
        vimage, mask = data[0].to(device), data[1].to(device)
        
        # æ¢¯åº¦æ¸…é›¶
        
        with autocast(device_type='cuda'): # æ··åˆç²¾åº¦è®­ç»ƒ
            # å‰å‘ä¼ æ’­ + åå‘ä¼ æ’­ + ä¼˜åŒ–
            optimizer.zero_grad()
            predicted_mask = model(vimage)
            mean_loss, et_loss, tc_loss, wt_loss = loss_function(predicted_mask, mask)
        scaler.scale(mean_loss).backward()                           # åå‘ä¼ æ’­ï¼Œåªæœ‰è®­ç»ƒæ¨¡å‹æ—¶æ‰éœ€è¦
        scaler.step(optimizer)                                  # ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
        scaler.update()  
        
        train_running_loss += mean_loss.item()                       # è®¡ç®—è®­ç»ƒlossçš„ç´¯è®¡å’Œ
        train_et_loss += et_loss.item() 
        train_tc_loss += tc_loss.item()
        train_wt_loss += wt_loss.item()
        
    return train_running_loss, train_et_loss, train_tc_loss, train_wt_loss

def val_one_epoch(model, Metric, val_loader, loss_function, epoch, device):
    """
    éªŒè¯è¿‡ç¨‹
    :param model: æ¨¡å‹
    :param metrics: è¯„ä¼°æŒ‡æ ‡
    :param train_loader: è®­ç»ƒæ•°æ®é›†
    :param val_loader: éªŒè¯æ•°æ®é›†
    :param scaler: ç¼©æ”¾å™¨
    :param optimizer: ä¼˜åŒ–å™¨
    :param loss_funtion: æŸå¤±å‡½æ•°
    :param device: è®¾å¤‡
    :param model_path: æ¨¡å‹è·¯å¾„
    """
    val_running_loss = 0.0
    Metrics_list = np.zeros((7, 4))
    model.eval()
    val_et_loss = 0.0
    val_tc_loss = 0.0
    val_wt_loss = 0.0
    
    with torch.no_grad(): # å…³é—­æ¢¯åº¦è®¡ç®—
        with autocast(device_type='cuda'):
            val_loader = tqdm(val_loader, desc=f"ğŸ§--Validating", leave=False)
            for data in val_loader:
                vimage, mask = data[0].to(device), data[1].to(device)                
                with autocast(device_type='cuda'):
                    predicted_mask = model(vimage)
                    mean_loss, et_loss, tc_loss, wt_loss = loss_function(predicted_mask, mask)
                    metrics = Metric.update(predicted_mask, mask)
                    Metrics_list += metrics
                val_running_loss += mean_loss.item() 
                val_et_loss += et_loss.item() 
                val_tc_loss += tc_loss.item()
                val_wt_loss += wt_loss.item()
    
        
    return val_running_loss, val_et_loss, val_tc_loss, val_wt_loss, Metrics_list

    

if __name__ == "__main__":
    
    # num_epochs = 10 
    # num_workers = 8
    # batch_size = 1
    # train_split = 0.8
    # val_split = 0.1
    # random_seed=42
    
    # device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    

    # # data_root = "/mnt/g/DATASETS/BraTS21_original_kaggle"
    # root = "/root/data/workspace/BraTS_segmentation/data_brats"
    # path_data = os.path.join(root, "BraTS2021_Training_Data")

    # # transform = transforms.Compose([
    # #     RandomCrop3D((144, 128, 128))
    # # ])
    # datasets = BraTS21_3d(path_data, local_train=True, length=10, data_size = (144,224,224))
    
    # # datasets_local = BraTS21_2d(local_dir,"t1", local_train=True, lenth=50)
    
    # model = UNet_3D(4, 4)
    # model.to(device)
    
    # val_metrics = EvaluationMetrics()
    
    # train_datasets, val_datasets, test_datasets = split_datasets(datasets, 
    #                                                         train_split=train_split,
    #                                                         val_split=val_split, 
    #                                                         random_seed=random_seed)
    # train_loader = DataLoader(train_datasets, 
    #                         batch_size = batch_size,
    #                         num_workers = num_workers,
    #                         shuffle=True)
    
    # val_loader = DataLoader(val_datasets, 
    #                         batch_size = batch_size,
    #                         num_workers=num_workers,
    #                         shuffle=False)
    # test_loader = DataLoader(test_datasets, 
    #                         batch_size = batch_size,
    #                         num_workers=num_workers,
    #                         shuffle=False)
    
    # # optimizer = Adam(model.parameters(), lr=1e-3)

    # # ä½¿ç”¨SGDä¼˜åŒ–å™¨
    # optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)
    # scaler = GradScaler()
    
    # # ä½¿ç”¨RMSPROPä¼˜åŒ–å™¨
    # # optimizer = RMSprop(model.parameters(), lr=1e-3, alpha=0.9, eps=1e-8)
 
    # # ä½¿ç”¨AdamWä¼˜åŒ–å™¨
    # # optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)
    # # loss_function = Diceloss()

    # loss_function = LossFunctions()

    # train_and_val(model, val_metrics, train_loader, val_loader, scaler, optimizer,  loss_function, num_epochs, device)

    pass