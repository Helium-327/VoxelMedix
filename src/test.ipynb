{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "def compute_hausdorff_distance(mask1, mask2):\n",
    "    \"\"\"\n",
    "    计算两个掩码之间的豪斯多夫距离。\n",
    "    \n",
    "    参数:\n",
    "    mask1 (torch.Tensor): 第一个掩码，形状为 (H, W) 或 (D, H, W)。\n",
    "    mask2 (torch.Tensor): 第二个掩码，形状为 (H, W) 或 (D, H, W)。\n",
    "    \n",
    "    返回:\n",
    "    float: 豪斯多夫距离。\n",
    "    \"\"\"\n",
    "    # 将掩码转换为点集\n",
    "    points1 = torch.nonzero(mask1).float()  # 获取非零元素的坐标\n",
    "    points2 = torch.nonzero(mask2).float()  # 获取非零元素的坐标\n",
    "    \n",
    "    # 将点集转换为 NumPy 数组，因为 scipy 的 directed_hausdorff 需要 NumPy 数组\n",
    "    points1_np = points1.cpu().numpy()\n",
    "    points2_np = points2.cpu().numpy()\n",
    "    \n",
    "    # 计算双向豪斯多夫距离\n",
    "    hd1 = directed_hausdorff(points1_np, points2_np)[0]\n",
    "    hd2 = directed_hausdorff(points2_np, points1_np)[0]\n",
    "    \n",
    "    # 取最大值作为豪斯多夫距离\n",
    "    hd = max(hd1, hd2)\n",
    "    \n",
    "    return hd\n",
    "\n",
    "def compute_h95(mask1, mask2):\n",
    "    \"\"\"\n",
    "    计算两个掩码之间的 H95 指标。\n",
    "    \n",
    "    参数:\n",
    "    mask1 (torch.Tensor): 第一个掩码，形状为 (H, W) 或 (D, H, W)。\n",
    "    mask2 (torch.Tensor): 第二个掩码，形状为 (H, W) 或 (D, H, W)。\n",
    "    \n",
    "    返回:\n",
    "    float: H95 指标。\n",
    "    \"\"\"\n",
    "    # 计算豪斯多夫距离\n",
    "    hd = compute_hausdorff_distance(mask1, mask2)\n",
    "    \n",
    "    # 计算 95 百分位数\n",
    "    h95 = np.percentile(hd, 95)\n",
    "    \n",
    "    return h95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# # 测试数据\n",
    "# batch_size = 2\n",
    "# num_classes = 4\n",
    "# spatial_dims = (128, 128, 128)\n",
    "\n",
    "# # 生成随机标签和预测张量\n",
    "# labels = torch.randint(0, 2, (batch_size, num_classes, *spatial_dims)).float()  # 标签\n",
    "# predictions = torch.randint(0, 2, (batch_size, num_classes, *spatial_dims)).float()  # 预测\n",
    "\n",
    "# # 计算每个样本和每个类别的 H95 指标\n",
    "# h95_results = torch.zeros(batch_size, num_classes)  # 存储 H95 结果\n",
    "\n",
    "# for i in tqdm(range(batch_size)):  # 遍历每个样本\n",
    "#     for j in tqdm(range(num_classes)):  # 遍历每个类别\n",
    "#         label_mask = labels[i, j]  # 获取当前样本和类别的标签掩码\n",
    "#         pred_mask = predictions[i, j]  # 获取当前样本和类别的预测掩码\n",
    "        \n",
    "#         # 计算 H95 指标\n",
    "#         h95 = compute_h95(label_mask, pred_mask)\n",
    "#         h95_results[i, j] = h95\n",
    "\n",
    "# print(\"H95 Results for each sample and class:\")\n",
    "# print(h95_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 128, 128, 128]), torch.Size([2, 4, 128, 128, 128]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pred = torch.rand([2, 4, 128, 128, 128]).float().to(device=device)\n",
    "mask = torch.randint(0, 4, [2, 128, 128, 128])\n",
    "mask = F.one_hot(mask).permute(0, 4, 1, 2, 3).float().to(device=device)\n",
    "\n",
    "pred.shape, mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_h95(pred, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m distance \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcdist(pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m), \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# min_distance_pred_to_mask = torch.min(distance, dim=1)[0]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "distance = torch.cdist(pred.view(2, -1, 4), mask.reshape(2, -1, 4).shape)\n",
    "# min_distance_pred_to_mask = torch.min(distance, dim=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2097152, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.reshape(2, -1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Deformable3DConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # 常规3D卷积用于特征提取\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        \n",
    "        # 偏移量预测分支（输出3*K^3个偏移量，对应三维坐标偏移）\n",
    "        self.offset_conv = nn.Conv3d(in_channels, 3 * kernel_size**3, \n",
    "                                   kernel_size, stride, padding)\n",
    "        \n",
    "        # 初始化偏移量卷积权重为零\n",
    "        nn.init.constant_(self.offset_conv.weight, 0)\n",
    "        nn.init.constant_(self.offset_conv.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 生成偏移量场 [B, 3*K^3, D, H, W]\n",
    "        offset = self.offset_conv(x)\n",
    "        \n",
    "        # 生成常规卷积的输出特征\n",
    "        base_feature = self.conv(x)\n",
    "        \n",
    "        # 获取输入特征图尺寸\n",
    "        B, C, D, H, W = x.shape\n",
    "        K = self.kernel_size\n",
    "        \n",
    "        # 生成采样网格\n",
    "        grid = self._get_grid(offset)\n",
    "        \n",
    "        # 可变形采样\n",
    "        deformed_feature = F.grid_sample(\n",
    "            x, \n",
    "            grid, \n",
    "            mode='bilinear',\n",
    "            padding_mode='zeros',\n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        # 重塑采样结果并进行卷积融合\n",
    "        deformed_feature = deformed_feature.view(B, C, K, K, K, D, H, W)\n",
    "        output = torch.einsum('bcklmnop,qcklmn->bqp', deformed_feature, self.conv.weight)\n",
    "        \n",
    "        return output + base_feature  # 残差连接\n",
    "\n",
    "    def _get_grid(self, offset):\n",
    "        B, _, D, H, W = offset.shape\n",
    "        K = self.kernel_size\n",
    "        \n",
    "        # 生成基础网格坐标\n",
    "        x_grid, y_grid, z_grid = torch.meshgrid(\n",
    "            torch.linspace(-1, 1, K),\n",
    "            torch.linspace(-1, 1, K),\n",
    "            torch.linspace(-1, 1, K)\n",
    "        )\n",
    "        base_grid = torch.stack((z_grid, y_grid, x_grid), 3)  # [K, K, K, 3]\n",
    "        base_grid = base_grid.unsqueeze(0).repeat(B, 1, 1, 1, 1)  # [B, K, K, K, 3]\n",
    "        \n",
    "        # 添加偏移量并归一化\n",
    "        offset = offset.permute(0, 2, 3, 4, 1).view(B, D, H, W, K, K, K, 3)\n",
    "        deformed_grid = base_grid + offset * 0.1  # 控制偏移量幅度\n",
    "        \n",
    "        return deformed_grid.reshape(B, D*K, H*K, W*K, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (6) does not match the number of dimensions (5) for operand 1 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      3\u001b[0m conv_layer \u001b[38;5;241m=\u001b[39m Deformable3DConv(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 输出维度：(batch_size, 64, 128, 128, 128)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m, in \u001b[0;36mDeformable3DConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 重塑采样结果并进行卷积融合\u001b[39;00m\n\u001b[1;32m     47\u001b[0m deformed_feature \u001b[38;5;241m=\u001b[39m deformed_feature\u001b[38;5;241m.\u001b[39mview(B, C, K, K, K, D, H, W)\n\u001b[0;32m---> 48\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbcklmnop,qcklmn->bqp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeformed_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;241m+\u001b[39m base_feature\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.10/site-packages/torch/functional.py:402\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    404\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (6) does not match the number of dimensions (5) for operand 1 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "# BraTS输入维度：(batch_size, 4, 128, 128, 128) 对应4个模态\n",
    "input_tensor = torch.randn(1, 4, 128, 128, 128)\n",
    "conv_layer = Deformable3DConv(in_channels=4, out_channels=64)\n",
    "output = conv_layer(input_tensor)  # 输出维度：(batch_size, 64, 128, 128, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Deformable3DConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        \n",
    "        # 偏移量生成卷积层（输出通道数为3倍卷积核体积）\n",
    "        self.offset_conv = nn.Conv3d(\n",
    "            in_channels,\n",
    "            3 * kernel_size**3,  # 每个采样点3个方向偏移\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding\n",
    "        )\n",
    "        \n",
    "        # 常规卷积层\n",
    "        self.conv = nn.Conv3d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding\n",
    "        )\n",
    "        \n",
    "    def _get_base_grid(self, x):\n",
    "        \"\"\"生成归一化基础网格坐标[-1, 1]\"\"\"\n",
    "        batch_size, _, D, H, W = x.size()\n",
    "        grid_d, grid_h, grid_w = torch.meshgrid(\n",
    "            torch.linspace(-1, 1, D, device=x.device),\n",
    "            torch.linspace(-1, 1, H, device=x.device),\n",
    "            torch.linspace(-1, 1, W, device=x.device),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        grid = torch.stack((grid_w, grid_h, grid_d), dim=-1)  # [D, H, W, 3]\n",
    "        return grid.unsqueeze(0).repeat(batch_size, 1, 1, 1, 1)  # [B, D, H, W, 3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 生成偏移量 [B, 3*k^3, D, H, W]\n",
    "        offsets = self.offset_conv(x)\n",
    "        batch_size, _, D, H, W = offsets.size()\n",
    "        \n",
    "        # 调整偏移量形状 [B, D, H, W, k^3, 3]\n",
    "        offsets = offsets.view(\n",
    "            batch_size, \n",
    "            self.kernel_size**3, \n",
    "            3, \n",
    "            D, H, W\n",
    "        ).permute(0, 3, 4, 5, 1, 2)\n",
    "        \n",
    "        # 生成基础网格 [B, D, H, W, 3]\n",
    "        grid = self._get_base_grid(x)\n",
    "        \n",
    "        # 生成卷积核相对偏移量\n",
    "        kernel_offset = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                torch.linspace(-1, 1, self.kernel_size, device=x.device),\n",
    "                torch.linspace(-1, 1, self.kernel_size, device=x.device),\n",
    "                torch.linspace(-1, 1, self.kernel_size, device=x.device),\n",
    "                indexing='ij'\n",
    "            ), dim=-1\n",
    "        ).view(-1, 3)  # [k^3, 3]\n",
    "        \n",
    "        # 应用相对偏移和可学习偏移\n",
    "        grid = grid.unsqueeze(4) + kernel_offset.view(1, 1, 1, 1, -1, 3)  # [B, D, H, W, k^3, 3]\n",
    "        grid = grid + offsets\n",
    "        \n",
    "        # 执行可变形采样\n",
    "        deformed_x = F.grid_sample(\n",
    "            input=x,\n",
    "            grid=grid,\n",
    "            mode='bilinear',\n",
    "            padding_mode='zeros',\n",
    "            align_corners=True\n",
    "        )\n",
    "        \n",
    "        # 应用常规卷积\n",
    "        return self.conv(deformed_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grid_sampler(): expected 5D input and grid with same number of dimensions, but got input with sizes [1, 4, 128, 128, 128] and grid with sizes [1, 128, 128, 128, 27, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      3\u001b[0m conv_layer \u001b[38;5;241m=\u001b[39m Deformable3DConv(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 输出维度：(batch_size, 64, 128, 128, 128)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m, in \u001b[0;36mDeformable3DConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m grid \u001b[38;5;241m=\u001b[39m grid \u001b[38;5;241m+\u001b[39m offsets\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# 执行可变形采样\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m deformed_x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzeros\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# 应用常规卷积\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(deformed_x)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.10/site-packages/torch/nn/functional.py:4910\u001b[0m, in \u001b[0;36mgrid_sample\u001b[0;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[1;32m   4902\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   4903\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4904\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4905\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malign_corners=True if the old behavior is desired. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4906\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee the documentation of grid_sample for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4907\u001b[0m     )\n\u001b[1;32m   4908\u001b[0m     align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4910\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grid_sampler(): expected 5D input and grid with same number of dimensions, but got input with sizes [1, 4, 128, 128, 128] and grid with sizes [1, 128, 128, 128, 27, 3]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# BraTS输入维度：(batch_size, 4, 128, 128, 128) 对应4个模态\n",
    "input_tensor = torch.randn(1, 4, 128, 128, 128)\n",
    "conv_layer = Deformable3DConv(in_channels=4, out_channels=64)\n",
    "output = conv_layer(input_tensor)  # 输出维度：(batch_size, 64, 128, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
