Importing from timm.models.layers is deprecated, please import via timm.layers
加载配置文件耗时: 0.00 s
加载配置文件耗时: 0.00 s
Total number of parameters: 15.89 M
当前日期文件夹 '/root/workspace/VoxelMedix/results/AttentionUnet_DiceLoss_AdamW_CosineAnnealingWarmRestarts' 已经创建。
当前时间文件夹 '/root/workspace/VoxelMedix/results/AttentionUnet_DiceLoss_AdamW_CosineAnnealingWarmRestarts/2025-01-15_20-28-50' 已经创建。
已加载数据集, 训练集: 50, 验证集: 10
+------------------------------+----------------------------------------------------------------------+
| Parameter                    | Value                                                                |
+==============================+======================================================================+
| training_epochs              | 20                                                                   |
+------------------------------+----------------------------------------------------------------------+
| training_batch_size          | 2                                                                    |
+------------------------------+----------------------------------------------------------------------+
| training_num_workers         | 8                                                                    |
+------------------------------+----------------------------------------------------------------------+
| training_early_stop_patience | 0                                                                    |
+------------------------------+----------------------------------------------------------------------+
| training_save_max            | 5                                                                    |
+------------------------------+----------------------------------------------------------------------+
| training_interval            | 1                                                                    |
+------------------------------+----------------------------------------------------------------------+
| training_tb                  | True                                                                 |
+------------------------------+----------------------------------------------------------------------+
| training_data_split          | False                                                                |
+------------------------------+----------------------------------------------------------------------+
| training_local               | True                                                                 |
+------------------------------+----------------------------------------------------------------------+
| training_train_length        | 100                                                                  |
+------------------------------+----------------------------------------------------------------------+
| training_val_length          | 20                                                                   |
+------------------------------+----------------------------------------------------------------------+
| training_test_length         | 10                                                                   |
+------------------------------+----------------------------------------------------------------------+
| model_name                   | attention_unet                                                       |
+------------------------------+----------------------------------------------------------------------+
| model_in_channel             | 4                                                                    |
+------------------------------+----------------------------------------------------------------------+
| model_mid_channel            | 32                                                                   |
+------------------------------+----------------------------------------------------------------------+
| model_out_channel            | 4                                                                    |
+------------------------------+----------------------------------------------------------------------+
| model_fusion_flag            | True                                                                 |
+------------------------------+----------------------------------------------------------------------+
| model_total_parms            | None                                                                 |
+------------------------------+----------------------------------------------------------------------+
| optimizer_type               | adamw                                                                |
+------------------------------+----------------------------------------------------------------------+
| optimizer_lr                 | 0.0001                                                               |
+------------------------------+----------------------------------------------------------------------+
| optimizer_wd                 | 1e-05                                                                |
+------------------------------+----------------------------------------------------------------------+
| optimizer_reduce_patience    | 3                                                                    |
+------------------------------+----------------------------------------------------------------------+
| optimizer_reduce_factor      | 0.9                                                                  |
+------------------------------+----------------------------------------------------------------------+
| scheduler_type               | CosineWarmupRestarts                                                 |
+------------------------------+----------------------------------------------------------------------+
| scheduler_cosine_T_0         | 10                                                                   |
+------------------------------+----------------------------------------------------------------------+
| scheduler_cosine_T_mult      | 2                                                                    |
+------------------------------+----------------------------------------------------------------------+
| scheduler_cosine_eta_min     | 1e-6                                                                 |
+------------------------------+----------------------------------------------------------------------+
| scheduler_cosine_T_max       | 200                                                                  |
+------------------------------+----------------------------------------------------------------------+
| loss_type                    | diceloss                                                             |
+------------------------------+----------------------------------------------------------------------+
| paths_root                   | /root/workspace/VoxelMedix                                           |
+------------------------------+----------------------------------------------------------------------+
| paths_data_root              | /root/workspace/VoxelMedix/data                                      |
+------------------------------+----------------------------------------------------------------------+
| paths_output                 | /root/workspace/VoxelMedix/output                                    |
+------------------------------+----------------------------------------------------------------------+
| paths_train_csv              | /root/workspace/VoxelMedix/data/raw/brats21_original/train.csv       |
+------------------------------+----------------------------------------------------------------------+
| paths_val_csv                | /root/workspace/VoxelMedix/data/raw/brats21_original/val.csv         |
+------------------------------+----------------------------------------------------------------------+
| paths_test_csv               | /root/workspace/VoxelMedix/data/raw/brats21_original/test.csv        |
+------------------------------+----------------------------------------------------------------------+
| paths_results_root           | /root/workspace/VoxelMedix/results                                   |
+------------------------------+----------------------------------------------------------------------+
| commit                       | debug                                                                |
+------------------------------+----------------------------------------------------------------------+
| config                       | /root/workspace/VoxelMedix/src/configs/2025_1_15/attention_unet.yaml |
+------------------------------+----------------------------------------------------------------------+
| resume                       | False                                                                |
+------------------------------+----------------------------------------------------------------------+
| resume_tb_path               | False                                                                |
+------------------------------+----------------------------------------------------------------------+
| total_parms                  | 15.89 M                                                              |
+------------------------------+----------------------------------------------------------------------+
| train_length                 | 100                                                                  |
+------------------------------+----------------------------------------------------------------------+
| val_length                   | 20                                                                   |
+------------------------------+----------------------------------------------------------------------+2025-01-15 20:28:50,452 - INFO - 开始训练, 训练轮数:20, AttentionUnet模型写入tensorBoard, 使用 AdamW 优化器, 学习率: 0.0001, 损失函数: DiceLoss

AttentionUnet模型写入tensorBoard, 使用 AdamW 优化器, 学习率: 0.0001, 损失函数: DiceLoss
=== Training on [Epoch 1/20] ===:
🛠️--Training:   0%|          | 0/50 [00:00<?, ?it/s]🛠️--Training:   2%|▏         | 1/50 [00:13<10:52, 13.32s/it]🛠️--Training:   4%|▍         | 2/50 [00:14<04:44,  5.93s/it]🛠️--Training:   6%|▌         | 3/50 [00:14<02:44,  3.50s/it]🛠️--Training:   8%|▊         | 4/50 [00:15<01:48,  2.36s/it]🛠️--Training:  10%|█         | 5/50 [00:15<01:17,  1.73s/it]🛠️--Training:  12%|█▏        | 6/50 [00:16<00:59,  1.35s/it]🛠️--Training:  14%|█▍        | 7/50 [00:17<00:47,  1.11s/it]🛠️--Training:  16%|█▌        | 8/50 [00:17<00:39,  1.05it/s]🛠️--Training:  18%|█▊        | 9/50 [00:18<00:34,  1.19it/s]🛠️--Training:  20%|██        | 10/50 [00:18<00:30,  1.30it/s]🛠️--Training:  22%|██▏       | 11/50 [00:19<00:28,  1.39it/s]🛠️--Training:  24%|██▍       | 12/50 [00:20<00:26,  1.46it/s]🛠️--Training:  26%|██▌       | 13/50 [00:20<00:24,  1.51it/s]🛠️--Training:  28%|██▊       | 14/50 [00:21<00:23,  1.54it/s]🛠️--Training:  30%|███       | 15/50 [00:22<00:22,  1.57it/s]🛠️--Training:  32%|███▏      | 16/50 [00:22<00:21,  1.60it/s]🛠️--Training:  34%|███▍      | 17/50 [00:23<00:20,  1.61it/s]🛠️--Training:  36%|███▌      | 18/50 [00:23<00:19,  1.62it/s]🛠️--Training:  38%|███▊      | 19/50 [00:24<00:19,  1.62it/s]🛠️--Training:  40%|████      | 20/50 [00:25<00:18,  1.63it/s]🛠️--Training:  42%|████▏     | 21/50 [00:25<00:17,  1.62it/s]🛠️--Training:  44%|████▍     | 22/50 [00:26<00:17,  1.62it/s]🛠️--Training:  46%|████▌     | 23/50 [00:26<00:16,  1.62it/s]🛠️--Training:  48%|████▊     | 24/50 [00:27<00:16,  1.61it/s]🛠️--Training:  50%|█████     | 25/50 [00:28<00:15,  1.62it/s]🛠️--Training:  52%|█████▏    | 26/50 [00:28<00:14,  1.62it/s]🛠️--Training:  54%|█████▍    | 27/50 [00:29<00:14,  1.61it/s]🛠️--Training:  56%|█████▌    | 28/50 [00:30<00:13,  1.61it/s]🛠️--Training:  58%|█████▊    | 29/50 [00:30<00:13,  1.61it/s]🛠️--Training:  60%|██████    | 30/50 [00:31<00:12,  1.61it/s]🛠️--Training:  62%|██████▏   | 31/50 [00:31<00:11,  1.60it/s]🛠️--Training:  64%|██████▍   | 32/50 [00:32<00:11,  1.60it/s]🛠️--Training:  66%|██████▌   | 33/50 [00:33<00:10,  1.61it/s]🛠️--Training:  68%|██████▊   | 34/50 [00:33<00:09,  1.62it/s]🛠️--Training:  70%|███████   | 35/50 [00:34<00:09,  1.63it/s]🛠️--Training:  72%|███████▏  | 36/50 [00:34<00:08,  1.63it/s]🛠️--Training:  74%|███████▍  | 37/50 [00:35<00:07,  1.64it/s]🛠️--Training:  76%|███████▌  | 38/50 [00:36<00:07,  1.64it/s]🛠️--Training:  78%|███████▊  | 39/50 [00:36<00:06,  1.64it/s]🛠️--Training:  80%|████████  | 40/50 [00:37<00:06,  1.64it/s]🛠️--Training:  82%|████████▏ | 41/50 [00:38<00:05,  1.63it/s]🛠️--Training:  84%|████████▍ | 42/50 [00:38<00:04,  1.62it/s]🛠️--Training:  86%|████████▌ | 43/50 [00:39<00:04,  1.64it/s]🛠️--Training:  88%|████████▊ | 44/50 [00:39<00:03,  1.65it/s]🛠️--Training:  90%|█████████ | 45/50 [00:40<00:03,  1.65it/s]🛠️--Training:  92%|█████████▏| 46/50 [00:41<00:02,  1.66it/s]🛠️--Training:  94%|█████████▍| 47/50 [00:41<00:01,  1.66it/s]🛠️--Training:  96%|█████████▌| 48/50 [00:42<00:01,  1.67it/s]🛠️--Training:  98%|█████████▊| 49/50 [00:42<00:00,  1.67it/s]🛠️--Training: 100%|██████████| 50/50 [00:43<00:00,  1.68it/s]                                                             - Train mean loss: 0.8475
- ET loss: 0.8287
- TC loss: 0.8336
- WT loss: 0.8802
- Cost time: 0.72mins ⏱️

=== Validating on [Epoch 1/20] ===:
🧐--Validating:   0%|          | 0/10 [00:00<?, ?it/s]🧐--Validating:  10%|█         | 1/10 [00:02<00:24,  2.68s/it]🧐--Validating:  20%|██        | 2/10 [00:02<00:10,  1.28s/it]🧐--Validating:  30%|███       | 3/10 [00:03<00:05,  1.21it/s]🧐--Validating:  40%|████      | 4/10 [00:03<00:03,  1.61it/s]🧐--Validating:  50%|█████     | 5/10 [00:03<00:02,  2.00it/s]🧐--Validating:  60%|██████    | 6/10 [00:04<00:01,  2.34it/s]🧐--Validating:  70%|███████   | 7/10 [00:04<00:01,  2.62it/s]🧐--Validating:  80%|████████  | 8/10 [00:04<00:00,  2.85it/s]🧐--Validating:  90%|█████████ | 9/10 [00:05<00:00,  3.01it/s]🧐--Validating: 100%|██████████| 10/10 [00:05<00:00,  3.12it/s]                                                               命令执行成功！耗时: 0.17秒
输出: COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME
main.py 22924 root    7u  IPv4 4336369      0t0  TCP *:x11-7 (LISTEN)

正在清理端口 6007 的占用...
命令执行成功！耗时: 0.07秒
输出: 
😃 正在启动 TensorBoard 面板...
日志路径: /root/workspace/VoxelMedix/results/AttentionUnet_DiceLoss_AdamW_CosineAnnealingWarmRestarts/2025-01-15_20-28-50/tensorBoard
命令执行成功！耗时: 0.00秒
输出: 
😃 TensorBoard 启动成功！
请访问 http://0.0.0.0:6007 查看 TensorBoard 面板。
=== [Epoch 1/20] ===
- Model:    AttentionUnet
- Optimizer:AdamW
- Scheduler:CosineAnnealingWarmRestarts
- LossFunc: DiceLoss
- Lr:       0.000100
- val_cost_time:10.5775s ⏱️
+---------------+--------+--------+--------+--------+
| Metric_Name   |   MEAN |     ET |     TC |     WT |
+===============+========+========+========+========+
| Dice          | 0.3046 | 0.3855 | 0.4133 | 0.115  |
+---------------+--------+--------+--------+--------+
| Jaccard       | 0.22   | 0.2794 | 0.3161 | 0.0644 |
+---------------+--------+--------+--------+--------+
| Accuracy      | 0.8721 | 0.9906 | 0.9827 | 0.6429 |
+---------------+--------+--------+--------+--------+
| Precision     | 0.2546 | 0.3423 | 0.3572 | 0.0644 |
+---------------+--------+--------+--------+--------+
| Recall        | 0.7058 | 0.5615 | 0.6578 | 0.8981 |
+---------------+--------+--------+--------+--------+
| F1            | 0.3189 | 0.4035 | 0.4349 | 0.1185 |
+---------------+--------+--------+--------+--------+
| F2            | 0.4096 | 0.4689 | 0.52   | 0.2399 |
+---------------+--------+--------+--------+--------+
Mean Loss: 0.7602, ET: 0.6943, TC: 0.6972, WT: 0.8891

✨Saved best@e1_AttentionUnet__diceloss0.7602_dice0.3046_2025-01-15_20-28-50_1.pth under /root/workspace/VoxelMedix/results/AttentionUnet_DiceLoss_AdamW_CosineAnnealingWarmRestarts/2025-01-15_20-28-50/checkpoints
=== Training on [Epoch 2/20] ===:
🛠️--Training:   0%|          | 0/50 [00:00<?, ?it/s]🛠️--Training:   2%|▏         | 1/50 [00:02<02:22,  2.91s/it]🛠️--Training:   4%|▍         | 2/50 [00:03<01:20,  1.68s/it]🛠️--Training:   6%|▌         | 3/50 [00:04<00:56,  1.20s/it]🛠️--Training:   8%|▊         | 4/50 [00:04<00:44,  1.03it/s]🛠️--Training:  10%|█         | 5/50 [00:05<00:38,  1.18it/s]🛠️--Training:  12%|█▏        | 6/50 [00:06<00:33,  1.30it/s]🛠️--Training:  14%|█▍        | 7/50 [00:06<00:30,  1.40it/s]🛠️--Training:  16%|█▌        | 8/50 [00:07<00:28,  1.46it/s]🛠️--Training:  18%|█▊        | 9/50 [00:08<00:27,  1.51it/s]🛠️--Training:  20%|██        | 10/50 [00:08<00:25,  1.54it/s]🛠️--Training:  22%|██▏       | 11/50 [00:09<00:24,  1.58it/s]🛠️--Training:  24%|██▍       | 12/50 [00:09<00:23,  1.59it/s]🛠️--Training:  26%|██▌       | 13/50 [00:10<00:23,  1.60it/s]🛠️--Training:  28%|██▊       | 14/50 [00:11<00:22,  1.62it/s]🛠️--Training:  30%|███       | 15/50 [00:11<00:21,  1.63it/s]🛠️--Training:  32%|███▏      | 16/50 [00:12<00:21,  1.62it/s]🛠️--Training:  34%|███▍      | 17/50 [00:12<00:20,  1.61it/s]🛠️--Training:  36%|███▌      | 18/50 [00:13<00:19,  1.60it/s]🛠️--Training:  38%|███▊      | 19/50 [00:14<00:19,  1.61it/s]🛠️--Training:  40%|████      | 20/50 [00:14<00:18,  1.61it/s]🛠️--Training:  42%|████▏     | 21/50 [00:15<00:17,  1.62it/s]🛠️--Training:  44%|████▍     | 22/50 [00:16<00:17,  1.61it/s]🛠️--Training:  46%|████▌     | 23/50 [00:16<00:16,  1.60it/s]🛠️--Training:  48%|████▊     | 24/50 [00:17<00:16,  1.61it/s]🛠️--Training:  50%|█████     | 25/50 [00:17<00:15,  1.61it/s]🛠️--Training:  52%|█████▏    | 26/50 [00:18<00:14,  1.62it/s]🛠️--Training:  54%|█████▍    | 27/50 [00:19<00:14,  1.62it/s]🛠️--Training:  56%|█████▌    | 28/50 [00:19<00:13,  1.63it/s]🛠️--Training:  58%|█████▊    | 29/50 [00:20<00:13,  1.61it/s]🛠️--Training:  60%|██████    | 30/50 [00:21<00:12,  1.60it/s]🛠️--Training:  62%|██████▏   | 31/50 [00:21<00:11,  1.60it/s]🛠️--Training:  64%|██████▍   | 32/50 [00:22<00:11,  1.59it/s]🛠️--Training:  66%|██████▌   | 33/50 [00:22<00:10,  1.60it/s]🛠️--Training:  68%|██████▊   | 34/50 [00:23<00:10,  1.59it/s]🛠️--Training:  70%|███████   | 35/50 [00:24<00:09,  1.61it/s]🛠️--Training:  72%|███████▏  | 36/50 [00:24<00:08,  1.63it/s]🛠️--Training:  74%|███████▍  | 37/50 [00:25<00:07,  1.64it/s]🛠️--Training:  76%|███████▌  | 38/50 [00:25<00:07,  1.65it/s]🛠️--Training:  78%|███████▊  | 39/50 [00:26<00:06,  1.66it/s]🛠️--Training:  80%|████████  | 40/50 [00:27<00:06,  1.66it/s]🛠️--Training:  82%|████████▏ | 41/50 [00:27<00:05,  1.67it/s]🛠️--Training:  84%|████████▍ | 42/50 [00:28<00:04,  1.68it/s]🛠️--Training:  86%|████████▌ | 43/50 [00:28<00:04,  1.67it/s]🛠️--Training:  88%|████████▊ | 44/50 [00:29<00:03,  1.66it/s]🛠️--Training:  90%|█████████ | 45/50 [00:30<00:03,  1.64it/s]🛠️--Training:  92%|█████████▏| 46/50 [00:30<00:02,  1.63it/s]🛠️--Training:  94%|█████████▍| 47/50 [00:31<00:01,  1.63it/s]🛠️--Training:  96%|█████████▌| 48/50 [00:32<00:01,  1.63it/s]🛠️--Training:  98%|█████████▊| 49/50 [00:32<00:00,  1.63it/s]🛠️--Training: 100%|██████████| 50/50 [00:33<00:00,  1.64it/s]                                                             - Train mean loss: 0.6539
- ET loss: 0.5269
- TC loss: 0.5440
- WT loss: 0.8906
- Cost time: 0.55mins ⏱️

=== Validating on [Epoch 2/20] ===:
🧐--Validating:   0%|          | 0/10 [00:00<?, ?it/s]🧐--Validating:  10%|█         | 1/10 [00:02<00:19,  2.21s/it]🧐--Validating:  20%|██        | 2/10 [00:02<00:08,  1.09s/it]                                                              Traceback (most recent call last):
  File "/root/workspace/VoxelMedix/src/main.py", line 437, in <module>
    main(args = argparse.Namespace(**flattened_args))
  File "/root/workspace/VoxelMedix/src/main.py", line 345, in main
    train(model,
  File "/root/workspace/VoxelMedix/src/train.py", line 140, in train
    val_running_loss, val_et_loss, val_tc_loss, val_wt_loss, Metrics_list= val_one_epoch(model, Metrics, val_loader, loss_function, epoch, device)
  File "/root/workspace/VoxelMedix/src/train_and_val.py", line 108, in val_one_epoch
    metrics = Metric.update(predicted_mask, mask)
  File "/root/workspace/VoxelMedix/src/evaluate/metrics.py", line 384, in update
    recall_scores = self.recall(y_pred, y_mask)
  File "/root/workspace/VoxelMedix/src/evaluate/metrics.py", line 148, in recall
    y_mask = F.one_hot(y_mask, num_classes=self.num_classes).permute(0, 4, 1, 2, 3).float() # one-hot
KeyboardInterrupt
